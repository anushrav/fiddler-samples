{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0c3549a",
   "metadata": {},
   "source": [
    "# Monitoring NLP data using Fiddler Vector Monotoring\n",
    "\n",
    "In this notebook we present the steps for using Fiddler NLP monitoring. Fiddler employs a vector-based monitoring approach that can be used to monitor data drift in multi-dimensional data such as NLP embeddings and images. In this notebook we show a use case for monitoring NLP embeddings to detect drift in text data.\n",
    "\n",
    "Fiddler is the pioneer in enterprise Model Performance Management (MPM), offering a unified platform that enables Data Science, MLOps, Risk, Compliance, Analytics, and LOB teams to **monitor, explain, analyze, and improve ML deployments at enterprise scale**. \n",
    "Obtain contextual insights at any stage of the ML lifecycle, improve predictions, increase transparency and fairness, and optimize business revenue.\n",
    "\n",
    "---\n",
    "\n",
    "You can experience Fiddler's NLP monitoring ***in minutes*** by following these five quick steps:\n",
    "\n",
    "1. Connect to Fiddler\n",
    "2. Fetch, prepare, and vectorize 20Newsgroup data\n",
    "2. Upload the vectorized baseline dataset\n",
    "3. Add metadata about your model\n",
    "4. Publish production events\n",
    "5. Get insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1db734",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99c2b2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -q fiddler-client\n",
    "\n",
    "import fiddler as fdl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import random\n",
    "import logging\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, stream=sys.stdout)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logger.info(f\"Running Fiddler client version {fdl.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e45386-30b7-4a2d-9ae3-26580261da07",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc2ed42-2cd9-424c-bc04-f8fcd3c01a69",
   "metadata": {},
   "source": [
    "# 1. Connect to Fiddler\n",
    "\n",
    "Before you can add information about your model with Fiddler, you'll need to connect using our API client.\n",
    "\n",
    "---\n",
    "\n",
    "**We need a few pieces of information to get started.**\n",
    "1. The URL you're using to connect to Fiddler\n",
    "2. Your organization ID\n",
    "3. Your authorization token\n",
    "\n",
    "The latter two of these can be found by pointing your browser to your Fiddler URL and navigating to the **Settings** page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21245781-c546-41de-9c18-9409361615e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://danny.trial.fiddler.ai' # Make sure to include the full URL (including https://).\n",
    "ORG_ID = 'danny'\n",
    "AUTH_TOKEN = 'qBVrDEtZfe9xWFZukYUGNSdWG004gWCD3drfNmfgNUg'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9678de-4d81-4b9b-905d-e2a6b0d8b141",
   "metadata": {},
   "source": [
    "Now just run the following code block to connect to the Fiddler API!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abb4cb3-907a-4405-866e-dd4591c4957b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = fdl.FiddlerApi(\n",
    "    url=URL,\n",
    "    org_id=ORG_ID,\n",
    "    auth_token=AUTH_TOKEN,\n",
    "    version=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88c43f3-1b5e-427d-92ed-307299d73bea",
   "metadata": {},
   "source": [
    "Once you connect, you can create a new project by specifying a unique project ID in the client's `create_project` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ba61dc-a436-4186-8b07-68fa429d34d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'simple_nlp_monitoring_example'\n",
    "\n",
    "if not PROJECT_ID in client.list_projects():\n",
    "    logger.info(f'Creating project: {PROJECT_ID}')\n",
    "    client.create_project(PROJECT_ID)\n",
    "else:\n",
    "    logger.info(f'Project: {PROJECT_ID} already exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090cbf24",
   "metadata": {},
   "source": [
    "# 2. Fetch, prepare and vectorize 20Newsgroup data\n",
    "\n",
    "In order to get insights into the model's performance, **Fiddler needs a small  sample of data that can serve as a baseline** for making comparisons with production inferences (aka. events).\n",
    "\n",
    "For this model's baseline dataset, we will use the __\"20 newsgroups text dataset\"__.  This dataset contains around 18,000 newsgroups posts on 20 topics. This dataset is available as one of the standard scikit-learn real-world datasets and can be be fechted directly using scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f839881",
   "metadata": {},
   "source": [
    "Let's first configure our baseline size and the topics present in the baseline.  For the baseline data, let's sample text data from topics related to compuers, sports, and politics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cb2e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_size = 2000 # number of records in the baseline dataset\n",
    "\n",
    "# Topics present in the baseline dataset\n",
    "baseline_cat = [\"comp.graphics\",\n",
    "                \"comp.sys.ibm.pc.hardware\",\n",
    "                \"comp.sys.mac.hardware\",\n",
    "                \"comp.windows.x\",\n",
    "                \"rec.autos\",\n",
    "                \"rec.motorcycles\",\n",
    "                \"rec.sport.baseball\",\n",
    "                \"rec.sport.hockey\",\n",
    "                \"talk.politics.guns\",\n",
    "                \"talk.politics.mideast\",\n",
    "                \"talk.politics.misc\",\n",
    "               ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa01d17-8407-475f-849f-e6adf1f16740",
   "metadata": {},
   "source": [
    "Use sklearn to fetch our baseline dataset of newsgroup posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483bc1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch newgroup posts within our categories and remove headers, footers, and quotes.\n",
    "data, labels = fetch_20newsgroups(\n",
    "    shuffle=True,\n",
    "    random_state=1,\n",
    "    remove=(\"headers\", \"footers\", \"quotes\"),\n",
    "    return_X_y=True,\n",
    "    categories=baseline_cat\n",
    ")\n",
    "\n",
    "# Remove carriage returns and filtering out special characters\n",
    "data_filtered = list(filter(None, [s.strip('\\n,=') for s in data]))\n",
    "\n",
    "# Sample 2000 random posts for our baseline\n",
    "base_samples = random.sample(data_filtered, baseline_size)\n",
    "base_series = pd.Series(base_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cec307",
   "metadata": {},
   "source": [
    "### Vectorization\n",
    "\n",
    "Fiddler monitors NLP and CV data by using encoded data in the form of embeddings, or **vectors**.  Before we load our baseline or our event data into the Fiddler platform for monitoring purposes, we must *vectorize* the raw NLP input.  \n",
    "\n",
    "The follow section provides two methods of vectorizing the NLP data: *TF-IDF vectorization* and *word2vec*.  Please run only 1 method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79ccda8-8b3c-46a2-9f05-147425aa1404",
   "metadata": {},
   "source": [
    "***Method 1: TF-IDF vectorization***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe13379",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_features=300, min_df=0.02, max_df=0.9, stop_words='english')\n",
    "vectorizer.fit(base_series)\n",
    "tfidf_baseline_sparse = vectorizer.transform(base_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9d40f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embedding_cols = vectorizer.get_feature_names_out().tolist()\n",
    "embedding_cols = ['f'+str(c+1) for c in range(len(embedding_cols))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec6086f",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_df = pd.DataFrame.sparse.from_spmatrix(tfidf_baseline_sparse, columns=embedding_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad3836f",
   "metadata": {},
   "source": [
    "\n",
    "***Method 2: word2vec by Spacy***\n",
    "\n",
    "The following lines show how to use ***word2vec*** embedding from Sacy. In order to run the following cell, you need to install spacy and its pre-trained models like 'en_core_web_lg'. See: https://spacy.io/usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb738aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "# s = time.time()\n",
    "# base_embeddings = base_series.apply(lambda sentence: nlp(sentence).vector)\n",
    "# print(f' Time to compute embeddings {time.time() - s}')\n",
    "\n",
    "# baseline_df = pd.DataFrame(base_embeddings.values.tolist())\n",
    "# baseline_df = baseline_df.rename(columns = {c:'f'+str(c+1) for c in baseline_df.columns})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372321de",
   "metadata": {},
   "source": [
    "### Add output, target and additional data columns\n",
    "\n",
    "The following section manufactures other columns needed for our baseline dataset, namely our output, target and some synthetic tabular features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7241d8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Synthetic income\n",
    "baseline_df['income'] = np.random.rand(baseline_size)*1000\n",
    "\n",
    "predictions = np.random.rand(baseline_size)\n",
    "targets = [1 if s>0.5 else 0 for s in predictions]\n",
    "\n",
    "baseline_df['predicted_score'] = predictions\n",
    "baseline_df['target'] = targets\n",
    "baseline_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08afe5f2-679c-4d75-be93-28f362361769",
   "metadata": {},
   "source": [
    "# 3. Upload the vectorized baseline dataset to Fiddler\n",
    "\n",
    "Next, let's create a [DatasetInfo](https://docs.fiddler.ai/reference/fdldatasetinfo) object to describe our baseline dataset and then [upload_dataset()](https://docs.fiddler.ai/reference/clientupload_dataset) to Fiddler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e879bf0d-202a-4b50-9a01-be834613c032",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ID = 'newsgroups1'  # The dataset name in Fiddler platform\n",
    "dataset_info = fdl.DatasetInfo.from_dataframe(baseline_df)\n",
    "\n",
    "if not DATASET_ID in client.list_datasets(project_id=PROJECT_ID):\n",
    "    logger.info(f'Upload dataset {DATASET_ID}')\n",
    "    \n",
    "    client.upload_dataset(\n",
    "        project_id=PROJECT_ID,\n",
    "        dataset_id=DATASET_ID,\n",
    "        dataset={'baseline': baseline_df},\n",
    "        info=dataset_info\n",
    "    )\n",
    "    \n",
    "else:\n",
    "    logger.info(f'Dataset: {DATASET_ID} already exists in Project: {PROJECT_ID}.\\n'\n",
    "               'The new dataset is not uploaded. (please use a different name.)') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed7fe54",
   "metadata": {},
   "source": [
    "# 4. Add metadata about the model\n",
    "\n",
    "Next we must tell Fiddler a bit more about our model.  This is done either by calling [.register_model()](https://docs.fiddler.ai/reference/clientregister_model) or [.add_model()](https://docs.fiddler.ai/reference/clientadd_model).  This notebook will use [.register_model()](https://docs.fiddler.ai/reference/clientregister_model) which will also create a surrogate model for you that will allow additional insight like feature impact and partial dependency analysis.  When calling [.register_model()](https://docs.fiddler.ai/reference/clientregister_model), we must pass in a [model_info](https://docs.fiddler.ai/reference/fdlmodelinfo) object to tell Fiddler about our model.  This [model_info](https://docs.fiddler.ai/reference/fdlmodelinfo) object will tell Fiddler about our model's task, inputs, output, target and which features are apart of the NLP vector created above.\n",
    "\n",
    "Let's first define our NLP vector using a custom feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae22304-27b1-49ce-aab2-0f9e316695e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "CF1 = fdl.CustomFeature.from_columns(embedding_cols, n_clusters=5, custom_name='vector1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd086fc6",
   "metadata": {},
   "source": [
    "Now let's define our [model_info](https://docs.fiddler.ai/reference/fdlmodelinfo) object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fbb4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify task\n",
    "model_task = 'binary'\n",
    "\n",
    "if model_task == 'regression':\n",
    "    model_task = fdl.ModelTask.REGRESSION\n",
    "    \n",
    "elif model_task == 'binary':\n",
    "    model_task = fdl.ModelTask.BINARY_CLASSIFICATION\n",
    "\n",
    "elif model_task == 'multiclass':\n",
    "    model_task = fdl.ModelTask.MULTICLASS_CLASSIFICATION\n",
    "\n",
    "elif model_task == 'ranking':\n",
    "    model_task = fdl.ModelTask.RANKING\n",
    "    \n",
    "    \n",
    "# Specify column types\n",
    "target = 'target'\n",
    "outputs = ['predicted_score']\n",
    "features = baseline_df.columns.drop('target', 'predicted_score')\n",
    "\n",
    "model_info = fdl.ModelInfo.from_dataset_info(\n",
    "    dataset_info = dataset_info,\n",
    "    dataset_id = DATASET_ID,\n",
    "    features = features,\n",
    "    target = target,\n",
    "    outputs = outputs,\n",
    "    custom_features = [CF1],\n",
    "    model_task=model_task,\n",
    "    binary_classification_threshold=0.5 #optional\n",
    ")\n",
    "model_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3bdc84",
   "metadata": {},
   "source": [
    "And call [.register_model()](https://docs.fiddler.ai/reference/clientregister_model) to tell Fiddler about our model and to create a model surrogate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7c506b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = 'newsgroup_classifier' # choose a different model ID\n",
    "\n",
    "if not MODEL_ID in client.list_models(project_id=PROJECT_ID):\n",
    "    client.register_model(\n",
    "        project_id=PROJECT_ID,\n",
    "        dataset_id=DATASET_ID,\n",
    "        model_id=MODEL_ID,\n",
    "        model_info=model_info\n",
    "    )\n",
    "else:\n",
    "    logger.info(f'Model: {MODEL_ID} already exists in Project: {PROJECT_ID}. Please use a different name.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8a387a-f1fc-4f6c-ae0b-247dbfbdb65f",
   "metadata": {},
   "source": [
    "# 5. Publish production events\n",
    "\n",
    "Let's manufacture some events we can publish to Fiddler.  Here, we will exploit the available topic tags to generate synethic data drift. We achieve this by changing the topics from which the event data are sampled compared to topics available in the baseline dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28176b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_batches=[]\n",
    "FRAC = 0.2 #sample size in each time interval as a fraction of baseline data\n",
    "\n",
    "#first bin is a random sample from baseline\n",
    "event_df = baseline_df.sample(frac=FRAC)\n",
    "event_batches.append(event_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c0597c",
   "metadata": {},
   "source": [
    "Generate events based on two groups of topics, each a subset of the baseline topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b170c4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "group1 = [\"rec.autos\",\n",
    "         \"rec.motorcycles\",\n",
    "         \"rec.sport.baseball\",\n",
    "         \"rec.sport.hockey\",\n",
    "         \"talk.politics.guns\",\n",
    "         \"talk.politics.mideast\",\n",
    "         \"talk.politics.misc\",]\n",
    "\n",
    "group2 = [\"talk.politics.guns\",\n",
    "         \"talk.politics.mideast\",\n",
    "         \"talk.politics.misc\",]\n",
    "\n",
    "event_categories = {'group1':group1, 'group2':group2}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce08ef2b-b963-4584-8fc1-b27528b59fc3",
   "metadata": {},
   "source": [
    "Now let's manufacture events by fetching the newsgroup data again just for each group above.  Pay attention to the vectorization step as it is different based on whether we used TF-IDF or word2vec above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808040d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#now generate events from specific groups\n",
    "\n",
    "for cat in event_categories.keys():\n",
    "    data, labels = fetch_20newsgroups(\n",
    "    shuffle=True,\n",
    "    random_state=1,\n",
    "    remove=(\"headers\", \"footers\", \"quotes\"),\n",
    "    categories=event_categories[cat],\n",
    "    return_X_y=True,\n",
    "    )\n",
    "    \n",
    "    event_size = int(baseline_size*FRAC)\n",
    "    \n",
    "    data_filtered = list(filter(None, [s.strip('\\n,=') for s in data]))\n",
    "    samples = pd.Series(random.sample(data_filtered,event_size))\n",
    "\n",
    "    # use the following lines for TF-IDF embedding\n",
    "    tfidf_embedding = vectorizer.transform(samples)\n",
    "    event_df = pd.DataFrame.sparse.from_spmatrix(tfidf_embedding, columns=embedding_cols)\n",
    "        \n",
    "    # use the following lines for word2vec embedding \n",
    "    #embeddings = samples.apply(lambda sentence: nlp(sentence).vector)\n",
    "    #event_df = pd.DataFrame(embeddings.values.tolist(), columns=embedding_cols)\n",
    "    \n",
    "    event_df['age'] = np.random.rand(event_size)*100\n",
    "                        \n",
    "    predictions = np.random.rand(event_size)\n",
    "    targets = [1 if s>0.5 else 0 for s in predictions]\n",
    "    event_df['predicted_score'] = predictions\n",
    "    event_df['target'] = targets\n",
    "\n",
    "    event_batches.append(event_df)\n",
    "    \n",
    "    #cat_text[cat] = samples\n",
    "    #cat_embeddings[cat] =  np.stack(embeddings.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26df7e15",
   "metadata": {},
   "source": [
    "Now let's manufacture timestamps for our event data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165a531d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating hourly bins. You can try daily bins by setting time_gap = 24*3600*1000\n",
    "time_gap = 3600*1000*2 \n",
    "\n",
    "#start from 23hrs ago\n",
    "timestamp=time.time()*1000 - 3600*12*1000\n",
    "for event_df in event_batches:\n",
    "    event_df['timestamp'] = timestamp\n",
    "    timestamp += time_gap  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eb5d2c",
   "metadata": {},
   "source": [
    "And, finally, publish our event groups in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac0083c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event_df in event_batches:\n",
    "    client.publish_events_batch(\n",
    "        project_id=PROJECT_ID,\n",
    "        model_id=MODEL_ID,\n",
    "        batch_source=event_df,\n",
    "        timestamp_field= 'timestamp' #comment this line if you are not adding timestamps\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf936e3-407b-4f1e-9374-3072930c4dc4",
   "metadata": {},
   "source": [
    "# 5. Get insights\n",
    "\n",
    "**You're all done!**\n",
    "  \n",
    "Now just head to your Fiddler URL and start getting enhanced observability into your model's performance.\n",
    "\n",
    "Run the following code block to get your URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b5c889-1235-4f6e-9b3d-a2c9f0bde956",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('/'.join([URL, 'projects', PROJECT_ID, 'models', MODEL_ID, 'monitor']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2c6ab4-7e7f-4342-8f92-964cd5314184",
   "metadata": {},
   "source": [
    "*Please allow 3-5 minutes for monitoring data to populate the charts.*\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"https://raw.githubusercontent.com/fiddler-labs/fiddler-samples/master/content_root/tutorial/quickstart/images/nlp1.png\" /></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**Questions?**  \n",
    "  \n",
    "Check out [our docs](https://docs.fiddler.ai/) for a more detailed explanation of what Fiddler has to offer.\n",
    "\n",
    "Join our [community Slack](http://fiddler-community.slack.com/) to ask any questions!\n",
    "\n",
    "If you're still looking for answers, fill out a ticket on [our support page](https://fiddlerlabs.zendesk.com/) and we'll get back to you shortly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cffe1b5-6419-4703-a1f7-b105b09352ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
